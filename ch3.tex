The data collected from the ATLAS data acquisition system must be compared to a set of simulated data. This dataset aims to mimic the different physics processes: it's production by the colliding beams, the evolution of the collision products within the detector and materials, and the detector's response to ultimately interpret efficiencies and background processes. Except for collision data, the output of all these data processing steps are stored in ROOT files. It starts off with Monte Carlo (MC) simulations, which is a computational technique that uses random sampling to generate events. Given these events, the interactions within the detector and the detector's response is simulated. This reconstructed product is called an Analysis Object Data (AOD), which are then cleaned by compressing the data and cutting any unnecessary events or columns into a finalized product called Derived AOD (DAOD). The products produced at each step are then stored into a compressed binary file, called a ROOT file, and are validated using different software tools. These tools collectively encompass the software framework called Athena \cite{atlas2019athena}. The flow of this process is display in Figure \ref{fig:DataChain}. This chapter will provide an introduction to ATLAS Open Data \cite{ATLAS_OpenData_DAODPHYSLITE_2015_2016}, ROOT, and its application programming interface (API) for TTree and RNTuple formats.
\begin{figure}
\centerline{\includegraphics[height=95mm]{ch3_images/datachain.png}}
\caption[DataChain]{ATLAS data chain-processing for data and Monte Carlo simulation \cite{ATLAS_Catmore_2020_DataProcessingChain}.}
\label{fig:DataChain}
\end{figure}

\section{ATLAS Open Data}
ATLAS Open Data is a publicly available dataset produced by the ATLAS collaboration. It's composed of MC simulations of particle collisions within the ATLAS detector and detector data measurements. The data used as inputs for the remainder of this study are MC simulations of top nominal samples from Run 2 \cite{ATLAS_OpenData_DAODPHYSLITE_MC_2024, ATLAS_OpenData_DAODPHYSLITE_EW_2024}. They are simulated processes that produce single top quarks and matter-antimatter $t\overline{t}$ pairs. The Feynman diagrams of these processes are shown in Figure \ref{fig: ttbar-feynman}.
\begin{figure}
\centerline{\includegraphics[width=\textwidth]{ch3_images/Single_quark_process_diagrams.png}}
\caption[DataChain]{Feynman diagrams of processes that produce single top quarks and $t\overline{t}$}
\label{fig: ttbar-feynman}
\end{figure}

The inputs are all provided in PHYSLITE format, which contains already-calibrated objects directly from an AOD or PHYS product \cite{ATLAS_Collaboration_2023_PHYSLITE}. Those objects include jets, electrons, muons, photons, taus and their kinematics, such as transverse momentum, mass, charge, eta, and phi. Each event contains a number of physical objects that depends on the underlying process, resulting in a multidimensional dataset. A full description of the variables can be found in Reference \cite{ATLAS_OpenData_PHYSLITE_Docs}.

\section{ROOT}
% history of ROOT
ROOT is a unified software package developed for processing, analyzing, visualizing and ultimately storing the massive high-energy physics datasets into ROOT files. Previously, high-energy experiments used FORTRAN-based libraries; however, an upgrade was needed to handle the scales and complexities of the data from the LHC. ROOT maintains an object-oriented structure, meaning it is organized around the data rather than the functions and logic. It's features include visualization tools such as histogramming, and statistical tools. ROOT can be used in C++ and python languages. Several subpackages exists for analysis such as RDataFrame.

\subsection{ROOT Compression Algorithms}
ROOT offers four different compression algorithms: \texttt{ZLIB}, \texttt{LZMA}, \texttt{LZ4}, and \texttt{ZSTD} \cite{Marcon:2024zsm}. Data compression allows users to store large files at reduced sizes without losing information from the original file. It can also increase data reading and writing speeds. There are generally two types of compression algorithms: lossless and lossy. Lossy algorithms reduce files at more depth and are irreversible processes. The four compression algorithms from ROOT are lossless algorithms, meaning they are reversible processes that reduce bits by eliminating statistical redundancy.  

There are advantages and disadvantages in each of the four algorithms. \texttt{LZ4} focuses on compression and decompression speed, yet provides large files. \texttt{LZMA} provides higher compression at the cost of significantly slower reading speeds. \texttt{ZLIB} is an older version of \texttt{ZSTD}. Both provide a balance between compression and reading speeds; however, \texttt{ZSTD} has been shown to perform better in all metrics in comparison to ZLIB \cite{BockelmanShadura_2021_ZstdLZ4}. The input data applied for this study were all produced with \texttt{ZSTD}. A comparison study between \texttt{ZSTD} and \texttt{LZ4} is performed for RNTuple versions of the inputs, shown in Chapter \ref{fourthchapter}.

\subsection{TTree Data Structure}
ROOT provides a data structure called TTree to store large amounts of columnar data efficiently. Usually scientific data is stored in what we call row-oriented formats such as a spreadsheet or CSV table. This format is well organized if one wants to access a single event, but viewing a single column then becomes inefficient, especially with large datasets. A TTree is columnar based, meaning it consists of a list of independent columns, called branches. Examples of branches can be event IDs or particle kinematics such as momentum in the x,y,z coordinates. Branches can hold integers, strings and std::vector data types. Buffers are automatically allocated behind each branch. Buffers are temporary storage areas for the independent binary version of the object. This is done to efficiently handle the writing and reading of the data to and from disk. Each branch has one or more baskets, which manages the in-memory buffer. In other words, a basket holds the values of a branch for a number of consecutive events. When a buffer is full, it is optionally compressed and then the corresponding basket is written to disk, leading to the creation of a new basket to hold the next entries. ROOT allows users to change buffersize parameters of the branch for personalized optimization. Figure \ref{fig:TTreeDataStructure} shows a more detailed flowchart of the TTree data structure.
\begin{figure}
\centerline{\includegraphics[height=130mm, width=.65\textwidth]{ch3_images/TTreeDataStructure.png}}
\caption[TTree Data Structure]{Example of the TTree Data Structure \cite{ROOT_TTree_v6-30}.}
\label{fig:TTreeDataStructure}
\end{figure}

\subsection{RNTuple Data Structure}
RNTuple is the new columnar data format that will be implemented at the start of the HL-LHC. It's design continues to be columnar based, as its predecessor TTree, but it now uses modern storage technologies for better performance charactersitics in data compactness, scalability, and read and write speed. For this reason RNTuple classes are backwards-incompatible to TTree both on the file format level and API level \cite{ROOT_RNTuple_BinaryFormatSpecification}. It's binary format version follows an \emph{epoch.major.minor.path} scheme, where \emph{epoch} indicates backward-incompatible changes, \emph{major} indicates forward-incompatible changes, \emph{minor} indicates new optional format features, and \emph{patch} indicates backported features from newer format verions. The remainder of this study uses the first public release of RNTuple 1.0.0.0.

RNTuple organizes data using an internal BLOB-based data layout and an external metadata schema. A BLOB (binary large object) is a collection of binary data stored as a single entity. For example, instead of embedding data directly into a database, data can be stored as a BLOB along with a unique identifier for later retreival. This is beneficial for managing large unstructured data \cite{GoogleCloud_BLOBstorage}. RNTuple uses a similar approach internally: Data is organized by columns of a single type and are attached to \emph{fields}, which describes a serialized C++ type. Columns are partitioned into \emph{pages}. Pages are compressed individually, similar to TTree baskets. \emph{Clusters} are sets of pages that contain all the data belonging to an entry range. \emph{Envelopes} are data blocks that contain metadata, such as field and columns types, cluster descriptions, and page locations. Overall, this structure allows for random-access of individual events without decompressing the entire dataset and for "fast merging" or concatenating RNTuples. A simplified diagram of the RNTuple structure in comparison to TTree is shown in Figure \ref{fig:RNTupleStructure}. 
\begin{figure}
\centerline{\includegraphics[width=\textwidth,height=90mm]{ch3_images/SerhanScreenshotRNTupleStructure.png}}
\caption[RNTuple Data Structure]{TTree Structure vs. RNTuple Structure \cite{ATLAS_Mete_Nowak_VanGemmeren_2024_RNTuple}.}
\label{fig:RNTupleStructure}
\end{figure}

\section{TTree vs. RNTuple API}
TTree's API is natively compatible with C++, RDataFrame analysis workflows in Python and C++, and the uproot library \cite{uproot}. At this stage, RNTuple's API is best compatible with RDataFrame analysis workflows and hand-written event loops. It currently has limited capabilities with the uproot library. The sections below will provide examples of RNTuple's API in comparison to TTree's. 

\subsection{Native C++ Event Loops}
Due to the multidimensional nature of particle physics data, event loops are common algorithms used in data analysis workflows. It is a process that continuously iterates through the large datasets to apply specific analysis steps to each event. As seen in Figure \ref{fig:eventloop-ttree}, users must iterate through TTree in order to load branches and define an empty pointer object to store their entries.
\begin{figure}
\centerline{\includegraphics[width=.8\textwidth,height=100mm]{ch3_images/ttree.png}}
\caption[C++ Event Loop with TTree]{Native C++ event loop using TTree. This script loads a PHYSLITE ROOT file containing a TTree titled "CollectionTree", and plots the distribution electron tranverse momenta.}
\label{fig:eventloop-ttree}
\end{figure}

The RNTuple interface uses smart pointers, which simulates a pointer while providing automatic memory management \cite{Smart_Pointer_Wikipedia}. This feature shortens the amount of code necessary to read and load data by a couple of lines. For example \texttt{RNTupleReader::Open} simultaneously loads the ROOT file and the RNTuple, as seen in Firgure \ref{fig:eventloop-rnt}. The function \texttt{GetView} also simultaneously loads and stores a field. 
\begin{figure}
\centerline{\includegraphics[width=\textwidth,height=90mm]{ch3_images/rntuple.png}}
\caption[C++ Event Loop with RNTuple]{This is the RNTuple version of Figure \ref{fig:eventloop-ttree}.}
\label{fig:eventloop-rnt}
\end{figure}

\subsection{RDataFrame in C++ and Python}
Analysis done with RDataFrame will mostly remain unmodified with RNTuple, as shown in Figure \ref{fig:rdfpython}, with the exception of filtering. Due to RNTuple's internal data structure, subfields such as "\texttt{AnalysisElectronsAuxDyn:pt}" are separated by their field, "\texttt{AnalysisElectronsAuxDyn}" by a column, instead of a period. This slight change confuses the filtering function in RDataFrame, but can be bypassed by assigning an alias name. Figure \ref{fig:rdfc} provides an example of how to read multiple inputs and apply a filter using RDataFrame in C++. 
\begin{figure}[h!]
\begin{subfigure}{\linewidth}
\centerline{\includegraphics[width = 0.8\linewidth]{ch3_images/ttree-rdf-python.png}}
\caption{Reading multiple TTree inputs.}
\end{subfigure}
\begin{subfigure}{\linewidth}
\centerline{\includegraphics[width=0.8\linewidth]{ch3_images/rnt-rdf-python.png}}
\caption{Reading multiple RNTuple inputs.}
\end{subfigure}
\caption[Reading Multiple Inputs in RDataFrame Python: TTree vs. RNTuple]{Examples of how to load multiple inputs into an RDataFrame in Python.}
\label{fig:rdfpython}
\end{figure}

\begin{figure}
\begin{subfigure}{\linewidth}
\centerline{\includegraphics[width = 0.8\linewidth]{ch3_images/ttree-rdf.png}}
\caption{Reading multiple TTree inputs.}
\end{subfigure}
\begin{subfigure}{\linewidth}
\centerline{\includegraphics[width=0.8\linewidth]{ch3_images/rnt-rdf.png}}
\caption{Reading multiple RNTuple inputs.}
\end{subfigure}
\caption[Applying an RDataFrame Filter in C++ Using Multiple Inputs]{Examples of how to load multiple inputs into an RDataFrame and create a new filtered dataframe in C++.}
\label{fig:rdfc}
\end{figure}



